{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9장. 파이썬을 데이터 수집하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 stdin과 stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#egrep.py\n",
    "import sys,re\n",
    "\n",
    "regex = sys.argv[1]\n",
    "\n",
    "for line in sys.stdin:\n",
    "    if re.search(regex,line):\n",
    "        sys.stdout.write(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#line_count.py\n",
    "import sys\n",
    "\n",
    "count = 0\n",
    "for line in sys.stdin:\n",
    "    count+=1\n",
    "    \n",
    "#출력값은 sys.stdout으로 보낸다.\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage:most_common_words.py num_words\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kang\\AppData\\Local\\conda\\conda\\envs\\ml_scratch\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#most_common_words.py\n",
    "\n",
    "import sys\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# 출력하고 싶은 단어의 수를 첫 번째 인자로 입력\n",
    "\n",
    "try:\n",
    "    num_works = int(sys.argv[1])\n",
    "except:\n",
    "    print(\"usage:most_common_words.py num_words\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "counter = Counter(word.lower() for line in sys.stdin for word in line.strip().split() if word)\n",
    "\n",
    "for word,count in counter.most_common(num_words):\n",
    "    sys.stdout.write(str(count))\n",
    "    sys.stdout.write(\"\\t\")\n",
    "    sys.stdout.write(word)\n",
    "    sys.stdout.write(\"\\n\")\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-c61a5e503872>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-c61a5e503872>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    type life.txt | python most_common_words.py 10\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "type life.txt | python most_common_words.py 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 파일읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'r'은 read_only(읽기전용)을 일컫는다.\n",
    "file_for_reading = open('life.txt','r',encoding='cp949')\n",
    "\n",
    "# 'w'는 write(쓰기)를 의미함 ( 해당 파일이 이미 존재한다면, 기존 파일을 제거함)\n",
    "#file_for_writing = open('life.txt','w',encoding='cp949')\n",
    "\n",
    "# 'a'는 append(덧붙이기)를 의미함 ( 해당의 맨 끝에 덧붙임)\n",
    "#file_for_appending = open('life.txt','a',encoding='cp949')\n",
    "\n",
    "# 작업이 끝났다면 파일을 닫는 것을 잊지말자!\n",
    "file_for_reading.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-90bfb0a5ace6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 이 시점부터는 f가 이미 종료되었기 떄문에 f를 다시 사용하지말자.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'process' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"life.txt\",'r') as f:\n",
    "    data = f\n",
    "# 이 시점부터는 f가 이미 종료되었기 떄문에 f를 다시 사용하지말자.\n",
    "process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 인생에 별 기대를 걸지마라!\n",
      "인생에 별 기대를 걸지 않고 사는 게 낫다. 과도한 기대는 과도한 절망을 가져온다.\n",
      "허무주의를 삶의 지표로 삼아라. 어려움과 고난이 닥쳐 오더라도 어느 정도 견뎌낼 수 있다.\n",
      "행복은 느긋한 체념에서 온다. 자존감, 의지력, 긍정적사고, 패기, 용기 등의 말로부터 스스로를 압박하고 괴롭히지 말아라.\n",
      "인간은 우주 속의 한알의 먼지같은 존재이다. 인간의 삶에 의미를 두지 말라. 그러면 작은 행복감이나마 맛보게 된다.\n",
      "굵고 짧게 살려고 하지마라. 가늘더라도 길게 살고 보는 것이 더 현명할 수도 있다.\n",
      "아무리 성공적인 삶을 산다해도 인간은 결국 죽는다. 죽은 후의 내세 따위는 없다.\n",
      "그런 것들은 전부 종교산업에 종사하며 명예와 부를 챙기는 자들의 세속적 욕심이 만들어낸 미끼일 뿐이다.\n",
      "\n",
      "2. 게을러져야 행복할 수 있다.\n",
      "바쁘고 부지런하게 일하는 사람들에 대해 열등감을 느끼지 마라. 그런 사람들은 머지않아 기계(육체)가 고장나서 죽는다.\n",
      "\n",
      "3. 싱글라이프가 행복의 지름길이다.\n",
      "결혼 안하고 외로운 것이 결혼하고서 온갖 스트레스에 시달리는 것보다 훨씬 낫다.\n",
      "굳이 같이 살고 싶다면 계약동거가 결혼보다 낫다.\n",
      "옛말에 '자식이 웬수, 무자식 상팔자'란 말이 괜히 나온게 아니다.\n",
      "\n",
      "4. 복습형, 예습형으로 본 행복론\n",
      "부모에 대한 일체의 원망이나 감사의 맘을 갖지 말아라.\n",
      "유교사상의 치명적 약점은 '옛날이 좋았다'라는 과거 집착이다. 그래서야 어찌 행복을 누리겟는가?\n",
      "불교사상 역시 현재 불행을 과거 탓으로 돌리랴고만 한다. 현재 불행은 인내해서 참을게 아니라 개선해야 하는 것이다.\n",
      "기독교 사상은 젤 심하다. 원죄라는 해괴망측한 망상에 얽매여 행복한 삶을 누리는 것에 반대한다.\n",
      "그때 그때 직감이 시키는대로 행동하라. 잔머리 굴리면 자연의 선물인 본원의 원시적 생명력을 잃게 된다.\n",
      "\n",
      "5. 있는 그대로의 나 자신을 받아들여라.\n",
      "조선왕조 시절 양반 쌍놈 구별이 있었듯이 지금고 귀족 평민의 구별이 있다. 돈 많으면 귀족이고 없으면 평민이다.\n",
      "평민에 속한다고 당장 자살할 게 아니라면 주어진 조건을 수긍하고 열심히 노력헤보는 수밖에 딴 도리가 없다.\n",
      "역경에 처했을 때는 절망으로 도피하거나 억울해하지 말고 자신의 실존을 직시하라. 맘을 가라앉히고\n",
      "자신의 운이 통할때까지 묵묵히 기다려야 한다. 궁즉통이다.\n",
      "제 잘난 맛으로 사는 사람은 행복하다. 괜한 열등감에 시달리지 마라.\n",
      "\n",
      "\n",
      "6. 정치에 관심 두지 마라.\n",
      "우리나라는 정치과잉이다. 정치 하나로 모든 것을 해결할 수 있다고 믿는 사람들이 많다.\n",
      "정치, 문화, 경제가 삼권분립을 이뤄야 나라도 행복해비고 국민들도 행복해진다.\n",
      "정치권력이 개인에게 미치는 힘을 최소로 해야 한다고 주장하는 '아나키즘'이 놓다고 본다.\n",
      "\n",
      "\n",
      "7.야한 본성에 충실하라.\n",
      "야한 마음을 갖고 살아야 행복해진다. '야한 마음'이란 도덕보다 본능에, 정신보다 육체에,\n",
      "아가페적 사랑보다 에로스적 사랑에, 질서보다 자유에, 전체보다 개인에, 검약보다 사치에가치를 매기는 마음이다.\n",
      "일해서 버는 돈을 섹스와 놀이를 위해서만 써라. 정신적 성취감(교회에 갖다 바치는 헌금 따위)를 위해서는 절대로 쓰지 마라!\n",
      "인간 예수가 말한 '너희는 어린아이같이 되지 않으면 천국에 들어갈 수 없다'는 얘기는 착하고 순수해야 천국에 살 수 있다는 얘기가 아니다.\n",
      "어린아이처럼 동물적으로 야한 욕심꾸러기가 되어야 살아 있을 때 행복하단 얘기다.\n",
      "\n",
      "\n",
      "8. 내일을 걱정하지 마라.\n",
      "인간 예수는 '내일 무엇을 먹을까 무엇을 입을까 걱정하지 마라'고 했다. 명언\n",
      "중의 명언이다. 미래 걱정에 사로잡히다 보면 오늘이 피폐해진다.\n",
      "인생의 장기적인 계획을 세워두지 않는게 좋다. 모든 일을 그때 그때 가서\n",
      "'벼락직관'과 '벼락치기'로 대처하는 것이 행복한 삶에 유리하다.\n",
      "행복한 삶은 미래를 차근차근 대비해가는 성실한 자세에서 이뤄지는 게 아니라\n",
      "미래에 대한 태연한 방심상태에서 이뤄진다.\n",
      "살아 있을때 실컷 쾌락을 즐겨라! 있지도 않은 내세를 위해 쾌락을 참아가며\n",
      "기도만 하고 있는 것처럼 바보 같은 짓은 없다.\n",
      "나는 지금까지 장편소설을 쓸 때 소설 전체의 줄거리와 플롯을 미리 구상해놓고 써본 적이 한 번도 없다.\n",
      "쓰다보면 어떻게든 굴러가겠지...하는 식으로 생각하고 처음 부분부터 우선 쓰고 본다.\n",
      "시작이 반이라고 그런식으로 맞춰 가다 보면 오느새 장편 소설 한 편이 완성되곤 했다.\n",
      "\n",
      "\n",
      "9. 건강과 행복\n",
      "비타민 노이로제에 걸리지 마라. 동물들은 그런 거 안먹어도 건강하게 잘들 산다.\n",
      "제약회사와 의사들의 합작에 의한 비타민 결핍 공포증에 속지마라.\n",
      "겅강하게 살려고 술끊고 담배끊고 무공해 자연식 고집하고...이런 식으로 살다보면 돌연사나 우울증에 걸리기 쉽다.\n",
      "본원적 본능을 억눌렀기 때문이다.\n",
      "최고의 건강법은 입에는 말이 적게, 머릿속에는 생각이 적게, 뱃속에는 음식이 적게 하는 것이다.\n",
      "대한민국 자살율은 세계 최고이다. 산다는 것 자체가 돌연사나 극심한 우울증의 원인이 되다. GDP가 아무리 높으면 뭐하나.\n",
      "질투, 중상모략, 튀는 놈 매장시키기, 상상을 초월하는 빈부격차 등 온갖 사회명이 만연한 대한민국을 용기있는 젊은이라면\n",
      "하루 빨리 뜨는 것이 행복한 삶을 유지하는 데 유리할 수 있다.\n",
      "많은 청소년들이 겪는 우울증이나 사살, 탈선 등의 원인은 한창 성욕이 끓어오르는 사춘기의 섹스(또는 대리만족을 위한 야동)를\n",
      "단지 미성년자라는 이유만으로 가로막는 이상한 법규 때문이다.\n",
      "성춘향과 이옹룡은 이미 15세에 질탕한 섹스를 즐겼다. 미성년자의 나이를 17세 정도로 개정하고 철저한 피임교육을 시킬 필요가 있다.\n",
      "자유를 주면 자율이 생긴다.\n",
      "\n",
      "\n",
      "10. 고독을 기쁘게 감수하라.\n",
      "혼자서 영화보고 카페이세 커피나 술을 마시고 한가로이 산책할할 수 있어야 고독을 두려워하지 않게 되어 행복해진다.\n",
      "마음속으로라도 가족관계로 인한 온갖 의무감에서 탈출해 스스로 홀로 독립하기를 시도해 보라. 그럼 차츰 행복해진다.\n",
      "일체의 모임이나 조직에 가입하지 말고 스스로 홀로되어 삶을 당당하게 살 수 잇어야 행복하다.\n",
      "옛말에 '군자의 사귐은 물맛같고 소인의 사귐은 꿀맛같다'...라는 좋은 말이 있다.\n",
      "고독한 일상에서 기쁨을 맛볼 수 있어야 한다. 혼자서 시간을 처리해 나가는 방법을 터득해애 한다.\n",
      "진한 우정도 없이 일부러 술친구, 수다친구를 만들 필요는 없다.\n",
      "\n",
      "\n",
      "11. 종교를 멀리하라.\n",
      "기독교에서는 모든 사람이 죄인이라고 가르친다. 그런 쓸데없는 죄의식은 그 사람을 불행으로 몰고 간다.\n",
      "기독교는 죗값에 대한 공포를 조장한다.\n",
      "예수는 석가는 만민평등주의와 휴머니즘을 설파한 사회개혁가였다.\n",
      "그러나 종교라는 권력집단이 우상화하여 이용하고 난 뒤부터 그들은 공포와 전율의 대상이 되어 버렸다.\n",
      "광적으로 종교에 빠져드는 사람은 정신의학자들은 일종의 정신병자로 본다. 그 사람의 삶은 이루 말할 수 없이 불행해진다.\n",
      "평생을 원인 모를 '죄의식'에 사로 잡혀 공포에 떨면서 산다면 도저히 행복해질 수가 없다.\n",
      "대부분의 종교는 죄의식을 지나치게 강조하면서 신도를 겁주고 윽박지른다.\n",
      "\n",
      "\n",
      "12. 마음의 행복에는 허무주의가 답이다.\n",
      "무슨일을 당하든 '대수롭지 않게' 생각할 수 있는 버릇을 들여야 한다. 과도하게 기뻐하거나 슬퍼할 필요도 없다.\n",
      "'천치같은 동심'으로 돌아가 무엇이든 덤덤해질 필요가 있다. 소금없는 음식을 먹는 것처럼.\n",
      "긍정적 허무주의야말로 고만으로 점철된 우리네 인생길에 위안을 줄 수 있는 유일한 친구가 된다.\n",
      "죽은 뒤의 일에 대한 관심을 끊고 오직 살아있을 때의 쾌락을 위해서만 살아가는 것...그것이 바로 퇘락주의적 허무주의의 요체다.\n",
      "인생은 어차피 허무하고 부질없는 짓이다. 특별히 악을 써봐야 결국 남는 건 씁쓸한 절망감 뿐이다. 죽음에 대한 공포는\n",
      "내세에 대한 공연한 기대심리로 이어지져 정신분열적 광신을 낳는다.\n",
      "육체적 쾌락에 대한 부정은 편협하고 가학적인 성품과 신경질적 적개심을 자겨다 준다.\n",
      "허무주의자는 과대망상적 정신질환을 앓지 않는다. 조울증에도 안걸린다.\n",
      "기대가 없으니 절망도 없고 평정한 정신상태를 유지할 수 있다.\n",
      "그들은 생의 본질이나 죽음의 본질 따위를 캐보려고 하지 않고\n",
      "흐르는 물처럼 인생을 담담하게 살아가기 떄문에 마음이 늘 행복하다.\n",
      "\n",
      "\n",
      "13. 용감보다는 비겁을 선택하라.\n",
      "을사늑약때 분에 못이겨 자결한 민영환 선생이, 자신이 비겁하다고 느끼더라도 악착같이 살아남아\n",
      "끈질긴 독립운동을 했더라면 조국에 훨씬 더 보탬이 되었을 것이다. 어떤 자살도 용감하지 않다. 남들이 비겁하다고 할지언정 질깃질깃\n",
      "살아남아 길게 보고 차근차근 목적을 이뤄 나가야 한다.\n",
      "\n",
      "\n",
      "14. 남의 눈치를 보지 말고 살아라.\n",
      "우리는 혼자 나왔다 혼자 죽는 외로운 인생이라는 사실을 잊지 말아야 한다. 부모, 형제, 남편(아내),친구...결국엔 다 소용없다.\n",
      "그러니 어떤 사람의 눈치도 보지 말고 의지도 말고 살아야 한다. 그러한 처신의 결과는 '실질적 행복'으로 내게 되돌아 온다.\n",
      "고독은 의존심에서 온다. 징징거리지 말고 당당한 나르시시즘으로 고독에 맞서야 한다.\n",
      "설사 욕을 얻어먹더라도 언제나 '독불장군'이 되어라. 그러는 것이 결국에 가서는 행복한 삶의 획득에 유리하다.\n",
      "진리가 너희를 자유케 하리라가 아니라 자유가 너희를 진리케 하리라가 맞다!\n"
     ]
    }
   ],
   "source": [
    "starts_with_hash = 0\n",
    "with open('life.txt','r') as file:\n",
    "    for line in file:\n",
    "        print(line.strip())\n",
    "        #if re.match(\"^#\",line):\n",
    "        #    starts_with_hash += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain(email_address):\n",
    "    return email_address.lower().split(\"@\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'naver.com'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_domain(\"kangcw2020@naver.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/email_addresses.txt','r') as f:\n",
    "    domain_counts = Counter(get_domain(line.strip()) for line in f if \"@\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'gmail.com': 28, 'ru.ac.za': 4, 'wits.ac.za': 3, 'ukzn.ac.za': 3, 'dut.ac.za': 3, 'unizulu.ac.za': 2, 'aims.ac.za': 2, 'uct.ac.za': 2, 'campus.ru.ac.za': 2, 'uclouvain.be': 2, 'yahoo.com': 1, 'yahoo.co.uk': 1, 'uofk.edu': 1, 'stu.ukzn.ac.za': 1, 'uj.ac.za': 1, 'sun.ac.za': 1, 'fis.ucm.es': 1, 'aip.de': 1, 'iburst.co.za': 1, 'kasi.re.kr': 1, 'ieec.uab.es': 1, 'icranet.org': 1, 'icra.it': 1, 'ehu.es': 1, 'myuct.ac.za': 1})\n"
     ]
    }
   ],
   "source": [
    "print(domain_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2.2 구분자가 있는 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6/20/2014', 'AAPL', '90.91']\n",
      "['6/20/2014', 'MSFT', '41.68']\n",
      "['6/20/2014', 'FB', '64.5']\n",
      "['6/19/2014', 'AAPL', '91.86']\n",
      "['6/19/2014', 'MSFT', '41.51']\n",
      "['6/19/2014', 'FB', '64.34']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"./data/tab_delimited_stock_prices.txt\",'r') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        print (row)\n",
    "        date = row[0]\n",
    "        symbol = row[1]\n",
    "        closing_price = float(row[2])\n",
    "        #process(date,symbol, closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('date', '6/20/2014'), ('symbol', 'AAPL'), ('closing_price', '90.91')])\n",
      "OrderedDict([('date', '6/20/2014'), ('symbol', 'MSFT'), ('closing_price', '41.68')])\n",
      "OrderedDict([('date', '6/20/2014'), ('symbol', 'FB'), ('closing_price', '64.5')])\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/chcolon_delimited_stock_prices.txt\",'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter=':')\n",
    "    for row in reader:\n",
    "        print (row)\n",
    "        date = row['date']\n",
    "        symbol = row['symbol']\n",
    "        closing_price = float(row['closing_price'])\n",
    "        #process(date,symbol, closing_price)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'today_prices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-df6eed4de60a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'comma_delimited_stock_prices.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mstock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtoday_prices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstock\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'today_prices' is not defined"
     ]
    }
   ],
   "source": [
    "with open('comma_delimited_stock_prices.txt','w') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for stock, price in today_prices.items():\n",
    "        writer.writerow([stock,price])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 웹 스크래핑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3.1 HTML과 파싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <html>\n",
    "#     <head>\n",
    "#         <title>A Web page</title>\n",
    "#     </head>\n",
    "    \n",
    "#     <body>\n",
    "#         <p id=\"author\">Joel Grus</p>\n",
    "#         <p id=\"subject\">Data Science</p>\n",
    "#     </body>\n",
    "# </html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "html = requests.get(\"https://wikidocs.net/book/1\").text\n",
    "soup = BeautifulSoup(html,'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_paragraph = soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_paragraph_text = soup.p.text\n",
    "first_paragraph_word = soup.p.text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'page_contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-da6c044279f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfirst_paragraph_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'page_contents'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfirst_paragraph_id2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'page_contents'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ml_scratch\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    995\u001b[0m         \"\"\"tag[key] returns the value of the 'key' attribute for the tag,\n\u001b[0;32m    996\u001b[0m         and throws an exception if it's not there.\"\"\"\n\u001b[1;32m--> 997\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'page_contents'"
     ]
    }
   ],
   "source": [
    "first_paragraph_id = soup.p['page_contents']\n",
    "first_paragraph_id2 = soup.p.get('page_contents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paragraphs = soup.find_all('p')\n",
    "paragraphs_with_ids = [p for p in soup('p') if p.get('id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p><strong> 점프 투 파이썬 오프라인 책 출간 !! (2016.03) </strong></p>,\n",
       " <p>이 책은 파이썬이란 언어를 처음 접해보는 독자들과 프로그래밍을 한 번도 해 본적이 없는 사람들을 대상으로 한다. 프로그래밍을 할 때 사용되는 전문적인 용어들을 알기 쉽게 풀어서 쓰려고 노력하였으며, 파이썬이란 언어의 개별적인 특성만을 강조하지 않고 프로그래밍 전반에 관한 사항을 파이썬이란 언어를 통해 알 수 있도록 알기 쉽게 설명하였다.</p>,\n",
       " <p>파이썬에 대한 기본적인 지식을 알고 있는 사람이라도 이 책은 파이썬 프로그래밍에 대한 흥미를 가질 수 있는 좋은 안내서가 될 것이다. 이 책의 목표는 독자가 파이썬을 통해 프로그래밍에 대한 전반적인 이해를 갖게하는 것이며, 또 파이썬이라는 도구를 이용하여 원하는 프로그램을 쉽고 재미있게 만들 수 있게 하는 것이다. </p>,\n",
       " <p><strong>[파이썬 2.7 or 파이썬 3]</strong> <br/>\n",
       " 점프 투 파이썬은 파이썬 <strong>3 버전</strong>을 기준으로 설명하고 있지만 파이썬 2.7을 사용하는 경우에도 무리없이 책을 읽을 수 있도록 서로 다른부분에 대한 설명도 포함하고 있다. (참고: <a href=\"https://wikidocs.net/743\">파이썬 2.7 vs 파이썬 3</a>)</p>,\n",
       " <p style=\"font-size:12px;\">※ 피드백은 저자에게 e-메일로 전달됩니다.</p>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_paragraphs = soup('p',{'class':'important'})\n",
    "important_paragraphs2 =soup('p','important')\n",
    "important_paragraphs3 = [p for p in soup('p') if 'important' in p.get('class',[])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans_inside_divs = [span\n",
    "                    for div in soup(\"div\")\n",
    "                    for span in div('span')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3.2 예시: 오라일리의 데이터 관련 책"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 링크로 들어가도 기존 오라일리 책에 서술 된 'thumbtext' 등의 태그 요소들이 검색되진 않지만, 해당 주소로 들어가면 검색결과가 나오긴 한다. 아마 태그 요소들이 다소 변경되서 검색이 되지 않은 듯 하다. 따라서 '2018-07-25'일을 기준하여 웹 페이지를 스크래핑하여 결과를 도출해보고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['2018-07-25'기준 링크 검색결과](./image/oreiley_bookdata_page.png)\n",
    "'2018-07-25'기준 링크 검색결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.safaribooksonline.com/search/?query=data\n",
    "- http://oreilly.com/terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해당 페이지에 html, css 소스코드가 명확히 나오지 않는다. 아마 javascript 기반으로 비동기적으로 자원들이 관리되거나 뒤늦게 자료들이 불러들여지기 때문인 듯 하다. 따라서 셀레니움을 통해서 소스를 불러들여오려고 한다.\n",
    "\n",
    "https://beomi.github.io/2017/02/27/HowToMakeWebCrawler-With-Selenium/\n",
    "\n",
    "#### 위의 주소에 셀레니움을 기반으로 하여, 웹 스크래핑을 하는 방법이 상세히 기술되어 있다. 해당 방법을 기반으로 진행하고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import time\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://shop.oreilly.com/category/browse-subjects/data.do?sortby=publicationDate&page=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"./util/chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에러1야 Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//a[@data-nav='js-next']\"}\n",
      "  (Session info: chrome=67.0.3396.99)\n",
      "  (Driver info: chromedriver=2.40.565498 (ea082db3280dd6843ebfb08a625e3eb905c4f5ab),platform=Windows NT 10.0.17134 x86_64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lastbooks = []\n",
    "num_pages = 5\n",
    "\n",
    "\n",
    "driver.get(base_url)\n",
    "time.sleep(20)\n",
    "for page_num in range(1, num_pages + 1):\n",
    "\n",
    "    \n",
    "    #링크 접속 후 대기시간\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    books = []\n",
    "\n",
    "    for td in soup('div', 'book-title'):\n",
    "        title = td.find(\"a\").text.strip()\n",
    "        books.append([title])\n",
    "\n",
    "    for count,td in enumerate(soup('div', 'chapter-meta')):\n",
    "        author = td.find(\"span\", \"author\").find(\"a\").text.replace(\"\\n\",\"\").strip()\n",
    "        publisher = td.find('span', 'publisher t-publisher').find(\"a\").text.replace(\"\\n\",\"\").strip()\n",
    "        publish_year= td.find('span', 'publish-date').text.split(\":\")[1].split()[1].strip()\n",
    "        publish_month= td.find('span', 'publish-date').text.split(\":\")[1].split()[0].strip()\n",
    "        books[count].extend([author,publisher,publish_year,publish_month])\n",
    "     \n",
    "    lastbooks.extend(books)\n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//a[@data-nav='js-next']\").click()\n",
    "    except Exception as e:\n",
    "        print(\"에러1야\",e)\n",
    "        break\n",
    "            \n",
    "    #링크 접속 후 대기시간\n",
    "    time.sleep(20)\n",
    "# for 문 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lastbooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_num in range(1, num_pages + 1):\n",
    "    print \"souping page\", page_num\n",
    "    url = base_url + str(page_num)\n",
    "    soup = BeautifulSoup(requests.get(url).text, 'html5lib')\n",
    "\n",
    "    for td in soup('td', 'thumbtext'):\n",
    "        if not is_video(td):\n",
    "            books.append(book_info(td))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     base_url = \"http://shop.oreilly.com/category/browse-subjects/\" + \\\n",
    "#            \"data.do?sortby=publicationDate&page=\"\n",
    "\n",
    "#     books = []\n",
    "\n",
    "#     for page_num in range(1, num_pages + 1):\n",
    "#         print \"souping page\", page_num\n",
    "#         url = base_url + str(page_num)\n",
    "#         soup = BeautifulSoup(requests.get(url).text, 'html5lib')\n",
    "            \n",
    "#         for td in soup('td', 'thumbtext'):\n",
    "#             if not is_video(td):\n",
    "#                 books.append(book_info(td))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_info(td):\n",
    "    return {\n",
    "        \"title\" : td[0],\n",
    "        \"author\" : td[1],\n",
    "        \"publisher\" : td[2],\n",
    "        \"publish_year\" : td[3],\n",
    "        \"publish_month\" : td[4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in lastbooks:\n",
    "    a.append(book_info(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[3]['publish_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(book[\"publish_year\"])\n",
    "\n",
    "def plot_years(plt, books):\n",
    "    # 2014 is the last complete year of data (when I ran this)\n",
    "    year_counts = Counter(book[\"publish_year\"] for book in lastbooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year_counts = Counter(book[\"publish_year\"] for book in a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'2018': 8, '2015': 1, '2017': 1})"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a1136e9c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "years = sorted(year_counts)\n",
    "book_counts = [year_counts[year] for year in years]\n",
    "plt.plot(years, book_counts)\n",
    "plt.ylabel(\"# of data books\")\n",
    "plt.title(\"Data is Big!\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import division\n",
    "# from collections import Counter\n",
    "# import math, random, csv, json\n",
    "\n",
    "# from bs4 import BeautifulSoup\n",
    "# import requests\n",
    "\n",
    "# ######\n",
    "# #\n",
    "# # BOOKS ABOUT DATA\n",
    "# #\n",
    "# ######\n",
    "\n",
    "# def is_video(td):\n",
    "#     \"\"\"it's a video if it has exactly one pricelabel, and if\n",
    "#     the stripped text inside that pricelabel starts with 'Video'\"\"\"\n",
    "#     pricelabels = td('span', 'pricelabel')\n",
    "#     return (len(pricelabels) == 1 and\n",
    "#             pricelabels[0].text.strip().startswith(\"Video\"))\n",
    "\n",
    "# def book_info(td):\n",
    "#     \"\"\"given a BeautifulSoup <td> Tag representing a book,\n",
    "#     extract the book's details and return a dict\"\"\"\n",
    "    \n",
    "#     title = td.find(\"div\", \"thumbheader\").a.text\n",
    "#     by_author = td.find('div', 'AuthorName').text\n",
    "#     authors = [x.strip() for x in re.sub(\"^By \", \"\", by_author).split(\",\")]\n",
    "#     isbn_link = td.find(\"div\", \"thumbheader\").a.get(\"href\")\n",
    "#     isbn = re.match(\"/product/(.*)\\.do\", isbn_link).groups()[0]\n",
    "#     date = td.find(\"span\", \"directorydate\").text.strip()\n",
    "    \n",
    "#     return {\n",
    "#         \"title\" : title,\n",
    "#         \"authors\" : authors,\n",
    "#         \"isbn\" : isbn,\n",
    "#         \"date\" : date\n",
    "#     }\n",
    "\n",
    "# from time import sleep\n",
    "\n",
    "# def scrape(num_pages=31):\n",
    "#     base_url = \"http://shop.oreilly.com/category/browse-subjects/\" + \\\n",
    "#            \"data.do?sortby=publicationDate&page=\"\n",
    "\n",
    "#     books = []\n",
    "\n",
    "#     for page_num in range(1, num_pages + 1):\n",
    "#         print \"souping page\", page_num\n",
    "#         url = base_url + str(page_num)\n",
    "#         soup = BeautifulSoup(requests.get(url).text, 'html5lib')\n",
    "            \n",
    "#         for td in soup('td', 'thumbtext'):\n",
    "#             if not is_video(td):\n",
    "#                 books.append(book_info(td))\n",
    "\n",
    "#         # now be a good citizen and respect the robots.txt!\n",
    "#         sleep(30)\n",
    "\n",
    "#     return books\n",
    "\n",
    "# def get_year(book):\n",
    "#     \"\"\"book[\"date\"] looks like 'November 2014' so we need to \n",
    "#     split on the space and then take the second piece\"\"\"\n",
    "#     return int(book[\"date\"].split()[1])\n",
    "\n",
    "# def plot_years(plt, books):\n",
    "#     # 2014 is the last complete year of data (when I ran this)\n",
    "#     year_counts = Counter(get_year(book) for book in books\n",
    "#                           if get_year(book) <= 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     years = sorted(year_counts)\n",
    "#     book_counts = [year_counts[year] for year in x]\n",
    "#     plt.bar([x - 0.5 for x in years], book_counts)\n",
    "#     plt.xlabel(\"year\")\n",
    "#     plt.ylabel(\"# of data books\")\n",
    "#     plt.title(\"Data is Big!\")\n",
    "#     plt.show()\n",
    "\n",
    "# ##\n",
    "# # \n",
    "# # APIs\n",
    "# #\n",
    "# ##\n",
    "\n",
    "# endpoint = \"https://api.github.com/users/joelgrus/repos\"\n",
    "\n",
    "# repos = json.loads(requests.get(endpoint).text)\n",
    "\n",
    "# from dateutil.parser import parse\n",
    "\n",
    "# dates = [parse(repo[\"created_at\"]) for repo in repos]\n",
    "# month_counts = Counter(date.month for date in dates)\n",
    "# weekday_counts = Counter(date.weekday() for date in dates)\n",
    "\n",
    "# ####\n",
    "# #\n",
    "# # Twitter\n",
    "# #\n",
    "# ####\n",
    "\n",
    "# from twython import Twython\n",
    "\n",
    "# # fill these in if you want to use the code\n",
    "# CONSUMER_KEY = \"\"\n",
    "# CONSUMER_SECRET = \"\"\n",
    "# ACCESS_TOKEN = \"\"\n",
    "# ACCESS_TOKEN_SECRET = \"\"\n",
    "\n",
    "# def call_twitter_search_api():\n",
    "\n",
    "#     twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "#     # search for tweets containing the phrase \"data science\"\n",
    "#     for status in twitter.search(q='\"data science\"')[\"statuses\"]:\n",
    "#         user = status[\"user\"][\"screen_name\"].encode('utf-8')\n",
    "#         text = status[\"text\"].encode('utf-8')\n",
    "#         print user, \":\", text\n",
    "#         print\n",
    "\n",
    "# from twython import TwythonStreamer\n",
    "\n",
    "# # appending data to a global variable is pretty poor form\n",
    "# # but it makes the example much simpler\n",
    "# tweets = [] \n",
    "\n",
    "# class MyStreamer(TwythonStreamer):\n",
    "#     \"\"\"our own subclass of TwythonStreamer that specifies\n",
    "#     how to interact with the stream\"\"\"\n",
    "\n",
    "#     def on_success(self, data):\n",
    "#         \"\"\"what do we do when twitter sends us data?\n",
    "#         here data will be a Python object representing a tweet\"\"\"\n",
    "\n",
    "#         # only want to collect English-language tweets\n",
    "#         if data['lang'] == 'en':\n",
    "#             tweets.append(data)\n",
    "\n",
    "#         # stop when we've collected enough\n",
    "#         if len(tweets) >= 1000:\n",
    "#             self.disconnect()\n",
    "\n",
    "#     def on_error(self, status_code, data):\n",
    "#         print status_code, data\n",
    "#         self.disconnect()\n",
    "\n",
    "# def call_twitter_streaming_api():\n",
    "#     stream = MyStreamer(CONSUMER_KEY, CONSUMER_SECRET, \n",
    "#                         ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "#     # starts consuming public statuses that contain the keyword 'data'\n",
    "#     stream.statuses.filter(track='data')\n",
    "    \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     def process(date, symbol, price):\n",
    "#         print date, symbol, price\n",
    "\n",
    "#     print \"tab delimited stock prices:\"\n",
    "\n",
    "#     with open('tab_delimited_stock_prices.txt', 'rb') as f:\n",
    "#         reader = csv.reader(f, delimiter='\\t')\n",
    "#         for row in reader:\n",
    "#             date = row[0]\n",
    "#             symbol = row[1]\n",
    "#             closing_price = float(row[2])\n",
    "#             process(date, symbol, closing_price)\n",
    "\n",
    "#     print\n",
    "\n",
    "#     print \"colon delimited stock prices:\"\n",
    "\n",
    "#     with open('colon_delimited_stock_prices.txt', 'rb') as f:\n",
    "#         reader = csv.DictReader(f, delimiter=':')\n",
    "#         for row in reader:\n",
    "#             date = row[\"date\"]\n",
    "#             symbol = row[\"symbol\"]\n",
    "#             closing_price = float(row[\"closing_price\"])\n",
    "#             process(date, symbol, closing_price)\n",
    "\n",
    "#     print\n",
    "\n",
    "#     print \"writing out comma_delimited_stock_prices.txt\"\n",
    "\n",
    "#     today_prices = { 'AAPL' : 90.91, 'MSFT' : 41.68, 'FB' : 64.5 }\n",
    "\n",
    "#     with open('comma_delimited_stock_prices.txt','wb') as f:\n",
    "#         writer = csv.writer(f, delimiter=',')\n",
    "#         for stock, price in today_prices.items():\n",
    "#             writer.writerow([stock, price])\n",
    "\n",
    "#     print \"BeautifulSoup\"\n",
    "#     html = requests.get(\"http://www.example.com\").text\n",
    "#     soup = BeautifulSoup(html)\n",
    "#     print soup\n",
    "#     print\n",
    "\n",
    "#     print \"parsing json\"\n",
    "\n",
    "#     serialized = \"\"\"{ \"title\" : \"Data Science Book\",\n",
    "#                       \"author\" : \"Joel Grus\",\n",
    "#                       \"publicationYear\" : 2014,\n",
    "#                       \"topics\" : [ \"data\", \"science\", \"data science\"] }\"\"\"\n",
    "\n",
    "#     # parse the JSON to create a Python object\n",
    "#     deserialized = json.loads(serialized)\n",
    "#     if \"data science\" in deserialized[\"topics\"]:\n",
    "#         print deserialized \n",
    "\n",
    "#     print\n",
    "\n",
    "#     print \"GitHub API\"\n",
    "#     print \"dates\", dates\n",
    "#     print \"month_counts\", month_counts\n",
    "#     print \"weekday_count\", weekday_counts\n",
    "\n",
    "#     last_5_repositories = sorted(repos,\n",
    "#                                  key=lambda r: r[\"created_at\"],\n",
    "#                                  reverse=True)[:5]\n",
    "\n",
    "#     print \"last five languages\", [repo[\"language\"] \n",
    "#                                   for repo in last_5_repositories]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 API 사용하기\n",
    "- API(Application Programming Interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4.1 JSON(그리고 XML)\n",
    "- jSON(Javascript Object Notation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Data Science Book',\n",
       " 'author': 'Joel Grus',\n",
       " 'publicationYear': 2014,\n",
       " 'topics': ['data', 'science', 'data science']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"title\":\"Data Science Book\",\n",
    "\"author\": \"Joel Grus\",\n",
    "\"publicationYear\":2014,\n",
    "\"topics\":[\"data\",\"science\",\"data science\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "serialized = \"\"\"{\"title\":\"Data Science Book\",\n",
    "\"author\": \"Joel Grus\",\n",
    "\"publicationYear\":2014,\n",
    "\"topics\":[\"data\",\"science\",\"data science\"]}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Data Science Book', 'author': 'Joel Grus', 'publicationYear': 2014, 'topics': ['data', 'science', 'data science']}\n"
     ]
    }
   ],
   "source": [
    "#JSON을 파이썬 dict로 파싱\n",
    "deserialized = json.loads(serialized)\n",
    "if \"data science\" in deserialized[\"topics\"]:\n",
    "    print (deserialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XML (eXtensible markup language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4.2 인증이 필요하지 않은 API 사용하기\n",
    "- 간단한 작업을 위해서 너무 많은 작업을 요구하는 API가 아닌 간단히 작업할 수 있는 깃허브 API를 살펴보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "endpoint = \"https://api.github.com/users/joelgrus/repos\"\n",
    "\n",
    "repos = json.loads(requests.get(endpoint).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-02-23T15:51:04Z'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos[1]['created_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위와 같이 date의 경우엔 (유니코드) 문자열로 되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "from collections import Counter\n",
    "\n",
    "dates = [parse(repo[\"created_at\"]) for repo in repos]\n",
    "month_counts = Counter(date.month for date in dates)\n",
    "weekday_counts = Counter(date.weekday() for date in dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' 날짜 묶음: ',\n",
       " [datetime.datetime(2017, 12, 2, 20, 13, 49, tzinfo=tzutc()),\n",
       "  datetime.datetime(2018, 2, 23, 15, 51, 4, tzinfo=tzutc()),\n",
       "  datetime.datetime(2017, 12, 19, 0, 12, 40, tzinfo=tzutc()),\n",
       "  datetime.datetime(2018, 1, 31, 23, 51, 16, tzinfo=tzutc()),\n",
       "  datetime.datetime(2013, 7, 5, 2, 2, 28, tzinfo=tzutc()),\n",
       "  datetime.datetime(2017, 5, 10, 17, 22, 45, tzinfo=tzutc()),\n",
       "  datetime.datetime(2013, 11, 15, 5, 33, 22, tzinfo=tzutc()),\n",
       "  datetime.datetime(2012, 9, 18, 4, 20, 23, tzinfo=tzutc()),\n",
       "  datetime.datetime(2016, 7, 19, 17, 34, 31, tzinfo=tzutc()),\n",
       "  datetime.datetime(2015, 11, 11, 14, 15, 36, tzinfo=tzutc()),\n",
       "  datetime.datetime(2016, 5, 31, 14, 33, 6, tzinfo=tzutc()),\n",
       "  datetime.datetime(2015, 6, 30, 0, 33, 3, tzinfo=tzutc()),\n",
       "  datetime.datetime(2013, 8, 21, 13, 26, 5, tzinfo=tzutc()),\n",
       "  datetime.datetime(2013, 8, 18, 5, 3, 41, tzinfo=tzutc()),\n",
       "  datetime.datetime(2015, 7, 30, 1, 54, 55, tzinfo=tzutc()),\n",
       "  datetime.datetime(2014, 11, 9, 2, 31, 24, tzinfo=tzutc()),\n",
       "  datetime.datetime(2013, 11, 10, 6, 52, 56, tzinfo=tzutc()),\n",
       "  datetime.datetime(2015, 4, 8, 1, 1, 47, tzinfo=tzutc()),\n",
       "  datetime.datetime(2016, 1, 8, 3, 33, 58, tzinfo=tzutc()),\n",
       "  datetime.datetime(2016, 1, 21, 6, 46, 49, tzinfo=tzutc()),\n",
       "  datetime.datetime(2013, 7, 1, 3, 36, 23, tzinfo=tzutc()),\n",
       "  datetime.datetime(2013, 2, 22, 0, 12, 38, tzinfo=tzutc()),\n",
       "  datetime.datetime(2016, 5, 21, 23, 57, 23, tzinfo=tzutc()),\n",
       "  datetime.datetime(2015, 7, 2, 21, 47, 55, tzinfo=tzutc()),\n",
       "  datetime.datetime(2016, 10, 23, 21, 28, 37, tzinfo=tzutc()),\n",
       "  datetime.datetime(2012, 2, 15, 4, 55, 49, tzinfo=tzutc()),\n",
       "  datetime.datetime(2017, 11, 21, 23, 59, 6, tzinfo=tzutc()),\n",
       "  datetime.datetime(2018, 1, 3, 0, 44, 38, tzinfo=tzutc()),\n",
       "  datetime.datetime(2017, 5, 23, 14, 0, 58, tzinfo=tzutc()),\n",
       "  datetime.datetime(2016, 7, 11, 15, 48, 39, tzinfo=tzutc())],\n",
       " '달의 갯수 세기: ',\n",
       " Counter({12: 2,\n",
       "          2: 3,\n",
       "          1: 4,\n",
       "          7: 6,\n",
       "          5: 4,\n",
       "          11: 5,\n",
       "          9: 1,\n",
       "          6: 1,\n",
       "          8: 2,\n",
       "          4: 1,\n",
       "          10: 1}),\n",
       " '요일의 갯수 세기: ',\n",
       " Counter({5: 2, 4: 5, 1: 7, 2: 7, 6: 4, 3: 3, 0: 2}))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" 날짜 묶음: \",dates, \"달의 갯수 세기: \",month_counts, \"요일의 갯수 세기: \",weekday_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[정렬 전]\n",
      "\n",
      "[112873601, '2017-12-02T20:13:49Z']\n",
      "[122641019, '2018-02-23T15:51:04Z']\n",
      "[114700287, '2017-12-19T00:12:40Z']\n",
      "[119758315, '2018-01-31T23:51:16Z']\n",
      "[11189868, '2013-07-05T02:02:28Z']\n",
      "\n",
      "\n",
      "[정렬 후]\n",
      "\n",
      "[122641019, '2018-02-23T15:51:04Z']\n",
      "[119758315, '2018-01-31T23:51:16Z']\n",
      "[116072695, '2018-01-03T00:44:38Z']\n",
      "[114700287, '2017-12-19T00:12:40Z']\n",
      "[112873601, '2017-12-02T20:13:49Z']\n"
     ]
    }
   ],
   "source": [
    "# 'Repos'란 리스트 안에 각각의 Dict형 변수를 뽑아낸 뒤 그 함수의 Date 값을 Key로 하여 분류한다.\n",
    "last_5_repositories = sorted(repos, key= lambda r: r[\"created_at\"], reverse = True)[:5]\n",
    "\n",
    "\n",
    "\n",
    "# 예시 출력\n",
    "print(\"\\n\\n[정렬 전]\\n\")\n",
    "for i in [[i['id'],i[\"created_at\"]] for count,i in enumerate(repos) if count < 5]:\n",
    "    print (i)\n",
    "print(\"\\n\\n[정렬 후]\\n\")\n",
    "for i in [[i['id'],i[\"created_at\"]] for i in last_5_repositories]:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HTML', 'Python', 'Python', 'Python', 'Python']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_5_languages = [repo[\"language\"] for repo in last_5_repositories]\n",
    "last_5_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4.3 API 찾기\n",
    ": 사이트의 developers 혹은 API라는 페이지에서 관련 내용을 찾거나 'Python 어떠한 api'라고 검색하여 필요한 라이브러리를 찾아볼 수 있다.\n",
    "\n",
    "- 파이썬 API 제공 https://www.pythonforbeginners.com/development/list-of-python-apis/\n",
    "- 파이썬 외에 다른 언어 기반으로 한 API https://www.programmableweb.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5 예시: 트위터 API 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-0b8b14dd233a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-0b8b14dd233a>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    api 부분은 생략하고 넘어갈 예정\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "api 부분은 생략하고 넘어갈 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
